\documentclass{article}
\usepackage{interspeech2006,amssymb,amsmath,epsfig}
\usepackage{hyperref} % For hyperlinks in the PDF

\usepackage{natbib} % Harvard style bib
\bibliographystyle{IEEEtranN}

\usepackage{lipsum} % Dummy text

\setcounter{page}{1}
\sloppy		% better line breaks
\ninept
%SM below a registered trademark definition
\def\reg{{\rm\ooalign{\hfil
     \raise.07ex\hbox{\scriptsize R}\hfil\crcr\mathhexbox20D}}}


\title{Dockerised Clouds: \\ A Comparative Study on Container Cluster Management Frameworks}

\makeatletter
\def\name#1{\gdef\@name{#1\\}}
\makeatother
\name{{\em Anthony Troy, Martin Somers and Marcelo Grossi}}

\address{School of Computing  \\
Dublin City University \\
Dublin 9, Ireland\\
{\small \tt\{anthony.troy3,martin.somers,marcelo.grossi2\}@mail.dcu.ie}
}


\begin{document}

\maketitle

\begin{abstract}
Containerisation is a recently resurged computing paradigm 
that is having a significant impact on how applications are being built, 
shipped and ran.\ Being interoperable in nature, container instances can be easily scaled
on a single host or across a cluster of hosts.\
Docker, albeit a relatively young project, 
has successfully established a container standard  
in Linux and poses itself as being production-ready.\ 
Increasingly, cluster management frameworks are providing 
first-class support for the Docker container standard and runtime. 
This includes established solutions such as Apache Mesos 
and Kubernetes.\ Docker now also includes its own native clustering
 tool, Swarm.
This paper considers Docker's production-readiness with respect
to native clustering capabilities and runtime interoperability.\
We review the current approaches and patterns forwarded by 
cluster management solutions to orchestrate distributed container clusters under Docker,\
and subsequently contribute a comparative analysis of two varying 
frameworks in this space, Kubernetes and Swarm.


\end{abstract}

\section{Introduction}
Containers have a long history in computing though much of their recent popularity 
surround the recent developments of both LXC and the Docker platform. 
The former can be described as a container execution environment,
or more formally, a Linux user space interface to 
access new kernel capabilities of achieving process isolation through namespaces
and cgroups \citep{Claus}. The latter is an open-source suite of tools managed by Docker Inc.\ which
extends upon container technology such as LXC, in turn 
allowing containers to behave like ``full-blown hosts in their own right" 
whereby containers have ``strong isolation, their own network and storage stacks, as well 
as resource management capabilities to allow friendly co-existence of multiple containers on a host" \citep{db}.
\par 
Uncertainties around Docker's maturity and production-readiness have been expressed \citep{Kereki, Powers, Merkel}, however 
over the last two years the states of both Docker and the containerisation ecosystem continue to rapidly progress.\
Last year Docker has seen an unprecedented increase in development, adoption and community uptake \citep{Merkel}. Most
notably was the introduction of customisable container execution environments. This means as opposed to LXC one can
``take advantage of the numerous isolation tools available" such as ``OpenVZ, systemd-nspawn, libvirt-sandbox, qemu/kvm, BSD Jails and Solaris Zones".
Also included in this 0.9 release was the new built-in container execution driver ``libcontainer", which replaced LXC as the default driver.
Going forward on all platforms Docker can now execute kernel features such as ``namespaces, control groups, capabilities, apparmor profiles, 
network interfaces and firewalling rules" predictably ``without depending on LXC" as an external dependency \citep{Hykes}. 
\par
Interestingly, libcontainer itself was the first project to provide a standard interface for making containers and managing their lifecycle.\
Subsequently the Docker CEO  announced the coming together of industry leaders and others in partnership with the Linux Foundation
to form a ``minimalist, non-profit, openly governed project" named The Open Container Initiative (OCI), with the purpose of defining 
``common specifications around container format and runtime" \citep{Golub}. 
Thereafter Docker donated its base container format and runtime, libcontainer, to be maintained by the OCI. 
\par
Amidst establishing a container standard, Docker has made significant headway in 
supporting multi-host cloud production environments. In terms of native tooling, in the last year Docker has implemented
a suite of tools for provisioning and orchestrating containers:
\begin{itemize}
\item \textbf{Docker Machine} allows one to provision Docker hosts, which are simply Linux virtual machines (VMs) supporting Docker, on a local machine or cloud. 
Its pluggable driver API currently supports ``provisioning Docker locally with Virtualbox as well as remotely" on cloud providers such Digital Ocean, AWS, Azure and VMware.
\item \textbf{Docker Swarm} is a clustering solution which takes the standard 
``Docker Engine and extends it to enable you to work on a cluster of containers". 
This in turn allows one to ``manage a resource pool of Docker hosts and schedule
containers to run transparently on top, automatically managing workload and providing fail-over services", whereby you can specify how each container is to be ran in the the cluster, in turn allowing one to orchestrate and choreograph local or cloud containers.
\item \textbf{Docker Compose} is the ``glue" allowing one to configure relationships between containers (called links) and define within a single configuration file a full container based application and it's interdependencies, along with resource needs (like memory or disk).
\end{itemize}
\noindent In many cases an existing cloud infrastructure depends upon one or more orchestration tools, for example 
Consul for service discovery. Typically, such tools cannot be migrated away from easily and in turn cause ``vendor lock-in".
Consequently, Docker have implemented this trio of orchestration tools in a generic way, 
providing ``a standard interface to service providers so that they can almost be used as plug-and-play solutions" on top of the Docker platform \citep{holla}.
\par
Backed by both the industry and community, Docker is now presented as a more mature and production-ready
platform. Notwithstanding this impressive growth, there yet exists no
formal topology for a fully, or partly, Dockerised cloud \citep{Claus}.\ Similarly,
so for there is no widely accepted solution for managing 
Docker container clusters.\
 This paper considers how primary cluster management activities are achievable on top of the Docker platform.
In doing so we review the interoperability of the Docker runtime and format with existing 
container management solutions. Subsequently, we forward a comparative study
on two contrasting solutions, Kubernetes and Docker Swarm. 
\par
The remainder of this paper is structured as follows. In
section two we overview service orchestration, discovery and configuration in Docker clusters. Following this, section three details our
reviews of Docker Swarm and Kubernetes. Finally, in section four we conclude this paper.


\section{Docker Cluster Management}
Practitioners and industry experts note that cluster management frameworks supporting Docker
vary greatly in terms of capability, architecture and target cluster proportion
\citep{goasguen, holla}. This is unsurprising when we consider that all infrastructures 
are not subject to same orchestration requirements and software release cycles.
For instance, slow moving infrastructures can be characterised as having infrequent application deployments,
 hard-coded service configurations and rare service failures which may not have an urgent impact. In contrast, more fast moving infrastructures feature continuous deployments and strong automation in terms of service configuration and recovery. 
 % maybe add more of an intro here

\subsection{Service orchestration}
Central to cloud cluster management is the ability to elastically provision and tear down clusters. Many cloud providers have introduced their own service orchestration tools such as CloudFormation from AWS and Heat by OpenStack \citep{Dudouet}. 
On a high-level, these tools simply define a cluster template which can be later orchestrated with possibly extended configurations. As previously mentioned, the native Docker orchestration tools support similar features that can clusterise multi-host containers. Docker Compose conceptually defines a similar template to that of Amazon's CloudFormation and allows one to perform orchestration tasks such as provisioning, destroying and scaling on per container basis.
\par
\citet{Claus} describe container-based clusters as consisting of several hosts which are ``virtual servers on hypervisors or possibly bare-metal servers", each of which typically runs several containers that are responsible for scheduling, load balancing and serving an application or service. Meaning containers can be distributed across one or more host machines wherein these hosts might be virtual servers running other services that must also be orchestrated.
\par
Slow moving infrastructures may not be availing of their provider's orchestration tools as doing so is simply not required. Clusters themselves are manually defined once and the scaling of nodes can be introduced during deployments or at scheduled downtime. Nevertheless, Docker Compose supports this manual workflow. Conversely, fast moving infrastructures profit from their provider's orchestration tools, leveraging them to automate tasks around cluster management.\ As discussed previously, Swarm is a native Docker clustering tool for containers which pools Docker engines together into a single virtual host. In conjunction with Docker Compose, it facilitates for transparent orchestration across container clusters. \citep{holla}.
\par
Cluster management frameworks aim to abstract and automate service orchestration activities such as provisioning, scaling, task scheduling, resource utilisation management and failover recovery. Some cloud providers have implemented such frameworks which sit on top of Swarm. For example, Amazon's EC2 Container Service (ECS) is one that uses a shared-state scheduling model to execute tasks on containerised EC2 instances via containers. Each host instance has a preinstalled ECS agent which allows clusterised containers communicate together and with the ECS console. Consequently, via scheduled tasks, ECS clusters can be transparently and dynamically orchestrated.
\par
Stand-alone Swarm or ECS may be fitting orchestration solutions for fast moving infrastructures, however larger-scale clouds that host hundreds or thousands of containers require high-level cluster management platforms such as Apache Mesos and Kubernetes. The former abstracts ``distributed hardware resources into
a single pool of resources" and can provide similar cluster management facilities to ECS when integrated with scheduling and service management tools such as Marathon. The later is a higher-level platform specifically designed for managing containerised applications across multiple hosts including mechanisms for service deployment, scaling and maintenance.

\subsection{Service discovery and configuration}

Service discovery and configuration management are central cluster management concepts in distributed systems and microservices-based architectures. Both of which are argued to overlap in nature. Service discovery can be described as an approach to achieve ``dynamic and automatic software system composition, configuration and adaptation" \citep{Yang}. Generally, service discovery implementations accomplish this by allowing application components/services discover information or configurations about their current and  neighbouring environments through a distributed key-value store.
\par
Whether operating under a fast or slow moving infrastructure, requiring a service discovery solution is generally related to having a service-orientated  architecture style. The more distributed a system becomes, the more regularly do services require information about their own and neighbouring environments. The tooling around service discovery ranges in terms of complexity and provided features. DNS (Domain Name Systems) is a well-known and commonly understood standard which allows us ``associate a name with the IP address of one or machines" where the name becomes an ``entry point to the IP address of the host running that service" \citep{Newman}. More advanced tools like Consul and Apache Zookeeper                                                                                             support both configuration management and service discovery. The former is designed specifically for service discovery and can use service health checking features to route traffic away from unhealthy nodes. The later is used for wider variety of cases such ``configuration management, synchronizing data between services, leader election, message queues and as a naming service" \citep{Newman}.
\par 
Container-based service discovery involves the ability to dynamically register and discover multi-host containers among their peers. \citet{holla} poses two techniques to accomplish discovery in Docker; integrating Swarm backend discovery tools or using default Docker features like names and links. Docker Swarm implements a hosted discovery service which uses generated tokens to discover cluster nodes. Being primarily concerned with orchestration, Swarm does not currently support dynamic service registration and configuration. However, to dynamically configure and manage the services in your containers one can use a discovery backend with Swarm such as Etcd, Consul or Zookeeper. 
\par
As previously highlighted, Docker Compose provides a mechanism to link named containers on the same host. This is accomplished by ``inserting the first container's IP address in /etc/hosts when starting the second container". Importantly, the IP address of a container living on a different host ``is not known by the docker daemon running in the current host". The ambassador container pattern achieves cross-host container linking between provider and consumer containers by dynamically configuring network connections through respective intermediate ambassador containers \citep{holla}.

\section{Study: Cluster Management Frameworks}
\lipsum[1]

\subsection{Docker Swarm}
A part of the docker's native ecosystem, swarm is docker's production-ready cluster management and orchestration tool. It allows for transparent scaling of docker containers across multiple hosts and because it serves the same docker daemon API it can be used seamlessly with any docker compatible tools (like Docker Compose, Dokky, Jenkins and others).
Swarm will run a swarm agent daemon in each node of the cluster and coordinate them using a pluggable discovery service back-end (which maintains a list of nodes in your cluster) and a swarm manager (that will actually control the whole cluster). The connection between the manager and agent nodes is made through a secure tcp connection (by means of TSL certificates). In previous versions of swarm the manager itself was the single point of failure of the cluster as there was no fail-over available. In the latest release however, version 1.0, a replication service for the manager has been developed whereby several manager instances will compete for leadership, making swarm a highly available solution.
\subsubsection{Networking}
Making use of the new networking feature of docker (as of version 1.9), the whole cluster is interconnected by a virtual network that can be manually configured to connect any nodes in private/global scopes. The overlay network driver is used by default which results in all nodes of a cluster to be on the same virtual network (and so able to intercommunicate out-of-the-box). This is a very powerful feature for multi-host configuration that is now supported natively by docker.
\subsubsection{Scheduling strategies}
When a new container is to be created, swarm uses one of three scheduling algorithms for determining in which node the image will be deployed to and subsequently ran.
\begin{itemize}
\item \textbf{Spread} as the name says will try to evenly spread the containers in as many nodes as possible, taking into account the available CPU and RAM and also the number of running containers. This is the default algorithm.
\item \textbf{Binpack} also considers the node's available resources but unlike spread, it will try to schedule as many containers on the same node as possible. This is the ideal algorithm for maximizing the number of running containers on the cluster, minimizing resource fragmentation.
\item \textbf{Random} simply assigns a new container to a node in random fashion, not taking into consideration any other measurements.
\end{itemize}
\subsubsection{Filtering}
To support more complex scheduling mechanism swarm also provides filtering to effectively subset the available nodes based on a given criteria.
\begin{itemize}
\item \textbf{Constraint}* uses key-value pairs that are set at node level and are used as labels to identify characteristics of the node. This filter can be used on container creation by the user to select only nodes with a particular feature (key-value pair). This approach has several practical use cases such as tagging nodes on their physical location (region=eu-ireland or region=us-west), the running environment (environment=production or environment=test), hardware characteristics (storage=ssd or gpu=nvidia) or any other logical partitioning.
\item \textbf{Affinity}* is used to create an "attraction" between containers (to run next to another container), images (to run on nodes that already have an image pulled) or a label (the label is created upon a containers creation).
\item \textbf{Port} considers exposed ports on the node as unique resources, and will try to schedule containers on nodes that have a particular port available.
\item \textbf{Dependency} will try to honour volume, network stack or link dependencies and schedule containers only on nodes that match.
\item \textbf{Health} will prevent scheduling of new containers on unhealthy nodes.
\end{itemize}
\textbf{*} Both constraint and affinity filters are hard enforced, which means that if the affinity or constraint is not met, the container will not be started. The user has an option to create the affinity or constraint in soft mode, which will make the scheduler disregard the filter and use the configured strategy in case the affinity or constraint is not met.
\subsubsection{Not yet implemented}
Swarm does not yet support (as of version 1.0) host rebalancing - where a host fails and needs to be rescheduled on another node. This is in the roadmap and should be released alongside Docker version 1.10 release [https://github.com/docker/swarm/wiki/0.6.0-Milestone-Project-Page].

\subsection{Kubernetes}
\lipsum[1]

\section{Conclusions}
\lipsum[1]


\vspace{-7.5mm}
\renewcommand{\refname}{\section{References}}
\bibliography{is2006_latex_template}

\end{document}
